# ML_Model/model_train.py (GÃœNCEL VERSÄ°YON)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import os
import glob
import joblib 

# --- PATH VE DOSYA AYARLARI ---
# BetiÄŸin bulunduÄŸu yerden Data_source/Processed_Data klasÃ¶rÃ¼ne giden mutlak yol
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROCESSED_DATA_DIR = os.path.join(os.path.dirname(CURRENT_DIR), 'Data_source', 'Processed_Data')

# Model ve Ticker eÅŸleme dosyalarÄ±nÄ±n kayÄ±t yolu (ML_Model klasÃ¶rÃ¼nÃ¼n iÃ§ine kaydeder)
MODEL_PATH = os.path.join(CURRENT_DIR, "random_forest_model.joblib")
MAPPER_PATH = os.path.join(CURRENT_DIR, "ticker_mapping.joblib")

# Modelleri kaydetmek iÃ§in klasÃ¶rÃ¼ oluÅŸtur
if not os.path.exists(CURRENT_DIR):
    os.makedirs(CURRENT_DIR)

# --- VERÄ° YÃœKLEME ---

def load_and_combine_data():
    """DÃ¶viz kurlarÄ±yla birleÅŸtirilmiÅŸ veri setlerini okur ve tek bir DataFrame'de birleÅŸtirir."""
    
    # Yeni oluÅŸturulan *_final_processed.csv dosyalarÄ±nÄ± bulur
    # BURADA GÃœNCEL DOSYA ADI KULLANILIYOR: *_final_processed.csv
    all_files = glob.glob(os.path.join(PROCESSED_DATA_DIR, "*_final_processed.csv"))
    
    if not all_files:
        print(f"HATA: Processed_Data klasÃ¶rÃ¼nde hiÃ§ *_final_processed.csv verisi bulunamadÄ±! LÃ¼tfen data_merger_fx.py'yi Ã§alÄ±ÅŸtÄ±rÄ±n.")
        return None
        
    all_data = []
    
    for file_path in all_files:
        df = pd.read_csv(file_path, index_col='Date', parse_dates=True)
        df['Ticker'] = os.path.basename(file_path).split('_')[0]
        all_data.append(df)
        
    combined_df = pd.concat(all_data)
    combined_df.dropna(inplace=True)
    
    print(f"TÃ¼m veriler birleÅŸtirildi. Toplam satÄ±r: {len(combined_df)}")
    return combined_df

# --- MODEL EÄÄ°TÄ°MÄ° ---

def train_and_save_model(data_df):
    """Random Forest modelini yeni Ã¶zelliklerle eÄŸitir ve kaydeder."""

    # Ticker sÃ¼tununu sayÄ±sal kategoriye dÃ¶nÃ¼ÅŸtÃ¼r
    data_df['Ticker_Encoded'] = data_df['Ticker'].astype('category').cat.codes

    # 1. Ã–zellikleri (X) ve Hedefi (Y) Belirleme
    features = [
        'Close', 'Open', 'High', 'Low', 'Volume', 
        'MA_10', 'RSI', 'Ticker_Encoded',
        
        # ğŸ‘‡ YENÄ° EKLEDÄ°KLERÄ°MÄ°Z
        'USD_TL',  # Dolar/TL kuru
        'EUR_TL'   # Euro/TL kuru
    ]
    target = 'Target_Close'
    
    X = data_df[features]
    Y = data_df[target]

    # 2. EÄŸitim ve Test KÃ¼melerine AyÄ±rma (Zamana baÄŸlÄ± ayÄ±rma)
    split_point = int(len(X) * 0.80)
    X_train, X_test = X[:split_point], X[split_point:]
    Y_train, Y_test = Y[:split_point], Y[split_point:]
    
    print(f"EÄŸitim seti boyutu: {len(X_train)}, Test seti boyutu: {len(X_test)}")

    # 3. Random Forest Modelini EÄŸitme
    print("Model eÄŸitimi baÅŸlÄ±yor (Dolar/Euro dahil)...")
    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    model.fit(X_train, Y_train)
    print("Model eÄŸitimi tamamlandÄ±.")

    # 4. PerformansÄ± DeÄŸerlendirme
    predictions = model.predict(X_test)
    mse = mean_squared_error(Y_test, predictions)
    r2 = r2_score(Y_test, predictions)

    print(f"\n--- Model PerformansÄ± ---")
    print(f"Hata Kare OrtalamasÄ± (MSE): {mse:.2f}")
    print(f"R-Kare Skoru (R2): {r2:.2f}")

    # 5. Modeli Kaydetme
    joblib.dump(model, MODEL_PATH)
    
    # Modelin kullandÄ±ÄŸÄ± Ticker kodlamasÄ±nÄ± da kaydetme (Backend API iÃ§in kritik)
    ticker_mapping = data_df[['Ticker', 'Ticker_Encoded']].drop_duplicates().set_index('Ticker').to_dict()['Ticker_Encoded']
    joblib.dump(ticker_mapping, MAPPER_PATH)
    
    print(f"\nModel ve EÅŸleyici baÅŸarÄ±yla kaydedildi: {os.path.basename(MODEL_PATH)} ve {os.path.basename(MAPPER_PATH)}")

# --- ANA Ã‡ALIÅTIRMA ---
if __name__ == "__main__":
    combined_data = load_and_combine_data()
    if combined_data is not None:
        train_and_save_model(combined_data)